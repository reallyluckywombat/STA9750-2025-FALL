---
title: "MP02: Making Backyards Affordable for All"
format: 
  html:
    theme: morph
    css: custom.css
    toc: true
    toc-location: right
    toc-depth: 3
    code-fold: true
---
# Executive Summary 
In this R project, I analyze data from the Bureau of Labor Statistics (BLS) and the U.S. Census Bureau on population, rent, income, employment, and housing growth across U.S. cities and metropolitan areas. Using these data, I develop a rent burden score and a housing growth index to evaluate how different regions perform relative to national averages. The analysis reveals important socio-economic patterns within Core-Based Statistical Areas (CBSAs) and provides insights that can help policymakers design data-driven housing strategies and improve affordability outcomes at the state and local levels.

# Data Acquisition
the Income, Rent, Population, and Household Dataset
```{r}
#| message: false
if(!dir.exists(file.path("data", "mp02"))){
    dir.create(file.path("data", "mp02"), showWarnings=FALSE, recursive=TRUE)
}

library <- function(pkg){
    ## Mask base::library() to automatically install packages if needed
    ## Masking is important here so downlit picks up packages and links
    ## to documentation
    pkg <- as.character(substitute(pkg))
    options(repos = c(CRAN = "https://cloud.r-project.org"))
    if(!require(pkg, character.only=TRUE, quietly=TRUE)) install.packages(pkg)
    stopifnot(require(pkg, character.only=TRUE, quietly=TRUE))
}

library(tidyverse)
library(glue)
library(readxl)
library(tidycensus)
if(!require("DT")) 
library(DT) 
library(ggplot2)
library(scales)
library(gghighlight)
library(RcppRoll)

get_acs_all_years <- function(variable, geography="cbsa",
                              start_year=2009, end_year=2023){
    fname <- glue("{variable}_{geography}_{start_year}_{end_year}.csv")
    fname <- file.path("data", "mp02", fname)
    
    if(!file.exists(fname)){
        YEARS <- seq(start_year, end_year)
        YEARS <- YEARS[YEARS != 2020] # Drop 2020 - No survey (covid)
        
        ALL_DATA <- map(YEARS, function(yy){
            tidycensus::get_acs(geography, variable, year=yy, survey="acs1") |>
                mutate(year=yy) |>
                select(-moe, -variable) |>
                rename(!!variable := estimate)
        }) |> bind_rows()
        
        write_csv(ALL_DATA, fname)
    }
    
    read_csv(fname, show_col_types=FALSE)
}

# Household income (12 month)
INCOME <- get_acs_all_years("B19013_001") |>
    rename(household_income = B19013_001)

# Monthly rent
RENT <- get_acs_all_years("B25064_001") |>
    rename(monthly_rent = B25064_001)

# Total population
POPULATION <- get_acs_all_years("B01003_001") |>
    rename(population = B01003_001)

# Total number of households
HOUSEHOLDS <- get_acs_all_years("B11001_001") |>
    rename(households = B11001_001)
```

Housing Permits Dataset
```{r}
get_building_permits <- function(start_year = 2009, end_year = 2023){
    fname <- glue("housing_units_{start_year}_{end_year}.csv")
    fname <- file.path("data", "mp02", fname)
    
    if(!file.exists(fname)){
        HISTORICAL_YEARS <- seq(start_year, 2018)
        
        HISTORICAL_DATA <- map(HISTORICAL_YEARS, function(yy){
            historical_url <- glue("https://www.census.gov/construction/bps/txt/tb3u{yy}.txt")
                
            LINES <- readLines(historical_url)[-c(1:11)]

            CBSA_LINES <- str_detect(LINES, "^[[:digit:]]")
            CBSA <- as.integer(str_sub(LINES[CBSA_LINES], 5, 10))

            PERMIT_LINES <- str_detect(str_sub(LINES, 48, 53), "[[:digit:]]")
            PERMITS <- as.integer(str_sub(LINES[PERMIT_LINES], 48, 53))
            
            data_frame(CBSA = CBSA,
                       new_housing_units_permitted = PERMITS, 
                       year = yy)
        }) |> bind_rows()
        
        CURRENT_YEARS <- seq(2019, end_year)
        
        CURRENT_DATA <- map(CURRENT_YEARS, function(yy){
            current_url <- glue("https://www.census.gov/construction/bps/xls/msaannual_{yy}99.xls")
            
            temp <- tempfile()
            
            download.file(current_url, destfile = temp, mode="wb")
            
            fallback <- function(.f1, .f2){
                function(...){
                    tryCatch(.f1(...), 
                             error=function(e) .f2(...))
                }
            }
            
            reader <- fallback(read_xlsx, read_xls)
            
            reader(temp, skip=5) |>
                na.omit() |>
                select(CBSA, Total) |>
                mutate(year = yy) |>
                rename(new_housing_units_permitted = Total)
        }) |> bind_rows()
        
        ALL_DATA <- rbind(HISTORICAL_DATA, CURRENT_DATA)
        
        write_csv(ALL_DATA, fname)
        
    }
    
    read_csv(fname, show_col_types=FALSE)
}

PERMITS <- get_building_permits()
```

The North American Industry Classification System (NAICS) coding system from the Bureau of Labor Statistics (BLS).
```{r}
#| message: false
library(httr2)
library(rvest)
get_bls_industry_codes <- function(){
    fname <- fname <- file.path("data", "mp02", "bls_industry_codes.csv")
    
    if(!file.exists(fname)){
    
        resp <- request("https://www.bls.gov") |> 
            req_url_path("cew", "classifications", "industry", "industry-titles.htm") |>
            req_headers(`User-Agent` = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0") |> 
            req_error(is_error = \(resp) FALSE) |>
            req_perform()
        
        resp_check_status(resp)
        
        naics_table <- resp_body_html(resp) |>
            html_element("#naics_titles") |> 
            html_table() |>
            mutate(title = str_trim(str_remove(str_remove(`Industry Title`, Code), "NAICS"))) |>
            select(-`Industry Title`) |>
            mutate(depth = if_else(nchar(Code) <= 5, nchar(Code) - 1, NA)) |>
            filter(!is.na(depth))
        
        naics_table <- naics_table |> 
            filter(depth == 4) |> 
            rename(level4_title=title) |> 
            mutate(level1_code = str_sub(Code, end=2), 
                   level2_code = str_sub(Code, end=3), 
                   level3_code = str_sub(Code, end=4)) |>
            left_join(naics_table, join_by(level1_code == Code)) |>
            rename(level1_title=title) |>
            left_join(naics_table, join_by(level2_code == Code)) |>
            rename(level2_title=title) |>
            left_join(naics_table, join_by(level3_code == Code)) |>
            rename(level3_title=title) |>
            select(-starts_with("depth")) |>
            rename(level4_code = Code) |>
            select(level1_title, level2_title, level3_title, level4_title, 
                   level1_code,  level2_code,  level3_code,  level4_code)
    
        write_csv(naics_table, fname)
    }
    
    read_csv(fname, show_col_types=FALSE)
    
}

INDUSTRY_CODES <- get_bls_industry_codes()
```

The BLS Quarterly Census of Employment and Wages.
```{r}
library(httr2)
library(rvest)
get_bls_qcew_annual_averages <- function(start_year=2009, end_year=2023){
    fname <- glue("bls_qcew_{start_year}_{end_year}.csv.gz")
    fname <- file.path("data", "mp02", fname)
    
    YEARS <- seq(start_year, end_year)
    YEARS <- YEARS[YEARS != 2020] # Drop Covid year to match ACS
    
    if(!file.exists(fname)){
        ALL_DATA <- map(YEARS, .progress=TRUE, possibly(function(yy){
            fname_inner <- file.path("data", "mp02", glue("{yy}_qcew_annual_singlefile.zip"))
            
            if(!file.exists(fname_inner)){
                request("https://www.bls.gov") |> 
                    req_url_path("cew", "data", "files", yy, "csv",
                                 glue("{yy}_annual_singlefile.zip")) |>
                    req_headers(`User-Agent` = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0") |> 
                    req_retry(max_tries=5) |>
                    req_perform(fname_inner)
            }
            
            if(file.info(fname_inner)$size < 755e5){
                warning(sQuote(fname_inner), "appears corrupted. Please delete and retry this step.")
            }
            
            read_csv(fname_inner, 
                     show_col_types=FALSE) |> 
                mutate(YEAR = yy) |>
                select(area_fips, 
                       industry_code, 
                       annual_avg_emplvl, 
                       total_annual_wages, 
                       YEAR) |>
                filter(nchar(industry_code) <= 5, 
                       str_starts(area_fips, "C")) |>
                filter(str_detect(industry_code, "-", negate=TRUE)) |>
                mutate(FIPS = area_fips, 
                       INDUSTRY = as.integer(industry_code), 
                       EMPLOYMENT = as.integer(annual_avg_emplvl), 
                       TOTAL_WAGES = total_annual_wages) |>
                select(-area_fips, 
                       -industry_code, 
                       -annual_avg_emplvl, 
                       -total_annual_wages) |>
                # 10 is a special value: "all industries" , so omit
                filter(INDUSTRY != 10) |> 
                mutate(AVG_WAGE = TOTAL_WAGES / EMPLOYMENT)
        })) |> bind_rows()
        
        write_csv(ALL_DATA, fname)
    }
    
    ALL_DATA <- read_csv(fname, show_col_types=FALSE)
    
    ALL_DATA_YEARS <- unique(ALL_DATA$YEAR)
    
    YEARS_DIFF <- setdiff(YEARS, ALL_DATA_YEARS)
    
    if(length(YEARS_DIFF) > 0){
        stop("Download failed for the following years: ", YEARS_DIFF, 
             ". Please delete intermediate files and try again.")
    }
    
    ALL_DATA
}

WAGES <- get_bls_qcew_annual_averages()
```
```{r}
#| message: false
library(stringr)
format_titles <- function(df){
  colnames(df) <- str_replace_all(colnames(df), "_", " ") |> 
    str_to_title()
  df}
```

# Data Integration and Exploration
## Task 2: Multi-Table Questions 
1. Which CBSA (by name) permitted the largest number of new housing units in the decade from 2010 to 2019 (inclusive)?
```{r}
T2.1 <- PERMITS |>
  filter(year >= 2010 & year <= 2019) |>
  slice_max(new_housing_units_permitted)|>
  inner_join(POPULATION, join_by(CBSA == GEOID))|>
  slice_head()|>
  pull(NAME)
```
**`r T2.1`** permitted the largest number of new housing units from 2010 to 2019


2. In what year did Albuquerque, NM (CBSA Number 10740) permit the most new housing units?

```{r}
#Creating a data table to see all of the new housing units 
#permitted for Albuquerque for the years documented. 
PERMITS |>
  filter(CBSA == 10740)|>
  format_titles() |>
  rename('CBSA' = 'Cbsa')|>
  datatable(options=list(searching=FALSE, info=FALSE))
```
We can see that in 2021, the NHUP is almost doubled from all of the other years. 
```{r}
T2.2 <- PERMITS |>
  filter(CBSA == 10740)|> 
  filter(!year == 2021) |>
  slice_max(new_housing_units_permitted)|>
  pull(year)
```
If we leave out this outlier, in **`r T2.2`**, Albuquerque, NM had the highest number of new housing permits

3. Which state (not CBSA) had the highest average individual income in 2015?

```{r}
# total income for every CBSA in 2015
T2.3_total_income <- INCOME |>
  filter(year == 2015)|>
  inner_join(HOUSEHOLDS, join_by(GEOID == GEOID))|>
  filter(year.y == 2015)|>
  group_by(GEOID)|>
  mutate(total_income = household_income * households)|>
  select(-NAME.y)|>
  mutate(state = str_extract(NAME.x, ", (.{2})", group=1))

# total income for every state
T2.3_state_income <- T2.3_total_income |>
  group_by(state)|>
  summarise(state_total_income = sum(total_income))

# total population in every state
T2.3_population_state <- POPULATION |>
  filter(year == 2015)|>
  mutate(state = str_extract(NAME, ", (.{2})", group=1))|>
  group_by(state)|>
  summarise(state_total_population = sum(population))

#Dividing total state income by total state population to find the average 
#individual income by state
T2.3_highest_indivi_income <- T2.3_state_income |>
  inner_join(T2.3_population_state, join_by(state == state))|>
  mutate(average_individual_income = state_total_income/state_total_population)|>
  slice_max(average_individual_income)|>
  pull(state)
```
**`r T2.3_highest_indivi_income`** had the highest average individual income in 2015. 

**For Fun:** Here is a datatable of all states' average individual incomes!
```{r}
T2.3_state_income |>
  inner_join(T2.3_population_state, join_by(state == state))|>
  mutate(average_individual_income = state_total_income/state_total_population)|>
  format_titles()|>
  datatable(options=list(searching=FALSE, info=FALSE))|>
  formatRound(c('State Total Income', 
                'State Total Population', 
                'Average Individual Income'), digits = 0)
```

4. What is the last year in which the NYC CBSA had the most data scientists in the country?
```{r}
#| results: "hide"
#Creating a GEOID column in the Wages table. We are removing the "c" and
#then adding a "0" to FIPS to join with GEOID
WAGES2 <- WAGES |>
  mutate(GEOID = paste0(gsub("C", "", FIPS), "0"))

#Now we can join the wage columns with the other tables!
#finding NYC's GeoID
POPULATION |>
  filter(NAME == 'New York-Newark-Jersey City, NY-NJ-PA Metro Area')|>
  pull(GEOID)

# Now that we know that NYC's GEOID is 35620, lets query the wage2 dataset
# to find the count of data scientists
T2.4 <- WAGES2 |>
  filter(INDUSTRY == 5182)|> # filtering for data professionals
  arrange(desc(EMPLOYMENT)) |> # ordering count of DP employment
  select(YEAR, EMPLOYMENT, GEOID)|> 
  group_by(YEAR)|>
  filter(EMPLOYMENT == max(EMPLOYMENT))|>
  filter(GEOID == 35620) |>
  head(n=1)|>
  pull(YEAR)
```
**`r T2.4`** was the last year in which the NYC CBSA had the most data scientists in the country

5. What fraction of total wages in the NYC CBSA was earned by people employed in the finance and insurance industries (NAICS code 52)? In what year did this fraction peak?
```{r}
#calculating the total wages from NYC GEOID 35620 
T2.5_totalwage_nyc <- WAGES2 |>
  filter(GEOID == 35620)|>
  summarise(totalwage_nyc = sum(TOTAL_WAGES))|>
  pull(totalwage_nyc)

#calculating total wages from NYC from Finance Employees
T2.5_totalwage_nyc_finance <- WAGES2 |>
  filter(GEOID == 35620)|>
  filter(INDUSTRY == 52)|>
  summarise(totalwage_nyc_finance = sum(TOTAL_WAGES))|> #total wages from NYC from Finance Employees
  pull(totalwage_nyc_finance)

T2.5_finance_fraction <- 
  T2.5_totalwage_nyc_finance/T2.5_totalwage_nyc
# it says 0.04086742, which is 4.08% idk that seems wrong, oddly low

#now what year did the fraction year... we have to group by year
T2.5_nyc_year <- WAGES2 |>
  filter(GEOID == 35620)|>
  group_by(YEAR)|>
  summarise(totalwage_nyc = sum(TOTAL_WAGES))

T2.5_nyc_year_finance <- WAGES2 |>
  filter(GEOID == 35620)|>
  filter(INDUSTRY==52)|>
  group_by(YEAR)|>
  summarise(totalfinancewage_nyc = sum(TOTAL_WAGES))

T2.5_peak <- T2.5_nyc_year |>
  inner_join(T2.5_nyc_year_finance, join_by(YEAR==YEAR))|>
  mutate(year_fraction = totalfinancewage_nyc/totalwage_nyc)|>
  arrange(desc(year_fraction))|>
  head(n=1)|>
  pull(YEAR)
```
**`r scales::percent(T2.5_finance_fraction)`** of total wages in the NYC CBSA was earned by people employed in the finance and insurance industries and this peaked in  **`r T2.5_peak`**.

## Task 3: Initial Visualizations
### The relationship between monthly rent and average household income per CBSA in 2009.
```{r}
#| message: false
T3.1 <- RENT |>
  filter(year==2009)|>
  inner_join(INCOME, join_by(GEOID==GEOID))|>
  filter(year.y==2009)|>
  select(GEOID,monthly_rent,household_income, year.x)

#plotting monthly rent and household income from 2009
ggplot(T3.1, aes(x=monthly_rent, y=household_income)) + 
  geom_point(color = "orange") +
  geom_smooth(method="lm") +
  xlab("Monthly Rent(USD$)") + 
  ylab("Average Household Income(USD$)") + 
  theme_bw() +
  ggtitle("Correlation of Monthly Rent and Average Household Income
          in 2009 by CBSA") +
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold",
                                  margin = margin(b = 8, t = 8)))
```

### The relationship between total employment and total employment in the health care and social services sector (NAICS 62) across different CBSAs.
```{r}
#| message: false
#| warning: false
T3.2_total<- WAGES2 |>
  group_by(GEOID,YEAR)|>
  summarise(total_employ = sum(EMPLOYMENT))|>
  ungroup()

T3.2_health <- WAGES2 |>
  filter(INDUSTRY == 62)|>
  group_by(GEOID, YEAR)|>
  summarise(health_employ = sum(EMPLOYMENT,na.rm = TRUE))|>
  filter(health_employ != 0)|>
  ungroup()

#creating a joined dataframe
T3.2_employment<- T3.2_total|>
  inner_join(T3.2_health, join_by(GEOID,YEAR))

T3.2_ratio <- T3.2_employment |>
  mutate(
    ratio = health_employ/ total_employ)

ggplot(T3.2_ratio, aes(x = YEAR, y = ratio, group = GEOID)) +
  geom_line(alpha = 0.3, color = "cadetblue4") +
  scale_y_log10(labels = scales::comma) +   # log scale helps with large variation
  xlab("Year") + 
  ylab("Employment Ratio (Health Care: Total") + 
  labs(
    title = "Ratio of Total Employment to Health Care 
    & Social Services Employment",
    subtitle = "Each line represents a different CBSA (GEOID)") +
  theme_bw() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5, face = "bold"))
```

### The evolution of average household size over time. Use different lines to represent different CBSAs.

```{r}
#| message: false
#| warning: false

POPULATION |>
  inner_join(HOUSEHOLDS, join_by(GEOID, year)) |>
  mutate(avg_housesize = population / households) |>
  ggplot(aes(x = year, y = avg_housesize, group = GEOID)) +
  geom_line(alpha = 0.1, size = .5,color = 'lightslateblue') +
  xlab("Year") + 
  ylab("Average Household Size") + 
  labs(
    title = "Average Household Size Over Time for Each GEOID") +
  theme_bw()
```

# Building Indices of Housing Affordability and Housing Stock Growth
## Task 4: Rent Burden
Baseline Value: **The national rent burden average(Z score) = 0**
```{r}
#Joining the INCOME and RENT tables and creating the rent_burden ratio
rent_income <- INCOME |>
  mutate(monthly_income = household_income/12)|>
  inner_join(RENT, join_by(GEOID, year))|>
  select(GEOID, year, NAME.x, monthly_income, monthly_rent)|>
  mutate(rent_burden = monthly_rent/monthly_income)

#Standardization and Scaling/Transformation:

#mean national rent burden ratio
national_rb_mean <- rent_income|>
  summarise(national_avg = mean(rent_burden))|>
  pull(national_avg)

#standard deviation of the national rent burden ratio
national_rb_sd <- rent_income|> 
  summarise(national_sd = sd(rent_burden))|>
  pull(national_sd)

#Z score column comparing the rent burden of each geoid and year to the SD 
rb_standardized <- rent_income |>
  mutate(rb_zscore = (rent_burden - national_rb_mean) / national_rb_sd)
```
### Rent Burden in Burlington, VT Metro Area Over Time

```{r}
rb_standardized |>
  filter(GEOID == 15540)|>
  select(-GEOID, -NAME.x)|>
  format_titles()|>
  rename('Z Score' = 'Rb Zscore')|>
  datatable(options=list(searching=FALSE, info=FALSE))|>
  formatRound(c('Monthly Income','Rent Burden', 'Z Score'))
```
### Cities with the Highest Rent Burden

```{r}
#| warning: false
highest_rb_cities <- rb_standardized |>
  filter(str_detect(NAME.x, "Metro")) |>
  group_by(GEOID) |>
  summarise(geoid_avg = mean(rb_zscore, na.rm = TRUE),
            NAME.x = first(NAME.x)) |>
  separate(NAME.x, into = c('City', 'State/Area'), sep = ',\\s')|> 
  mutate(City = recode(City,
                       "San Germ?n-Cabo Rojo" = "San Germán-Cabo Rojo",
                       "Aguadilla-Isabela-San Sebasti?n" = "Aguadilla-Isabela-San Sebastián",
                       'Mayag?ez' = 'Mayagüez'))|>
  slice_max(geoid_avg, n = 20)

highest_rb_cities |>
  rename('Average Annual Z Score'= 'geoid_avg')|>
  datatable(options=list(searching=FALSE, info=FALSE))|>
  formatRound(c('Average Annual Z Score'))
```
### Cities with the Lowest Rent Burden
```{r}
#| warning: false
lowest_rb_cities <- rb_standardized |>
  filter(str_detect(NAME.x, "Metro")) |>
  group_by(GEOID) |>
  summarise(geoid_avg = mean(rb_zscore, na.rm = TRUE),
            NAME.x = first(NAME.x)) |>
  separate(NAME.x, into = c('City', 'State/Area'), sep = ',\\s')|> 
  slice_min(geoid_avg, n = 20)

lowest_rb_cities |>
  rename('Average Annual Z Score'= 'geoid_avg')|>
  datatable(options=list(searching=FALSE, info=FALSE))|>
  formatRound(c('Average Annual Z Score'))
```

## Task 5: Housing Growth

### Constructing the Instantaneous Measure
```{r}
#| warning: false
#Joining POPULATION and PERMITS
POP_PERMITS <- POPULATION |>
  inner_join(PERMITS, join_by(GEOID == CBSA, year == year))

#‘instantaneous’: metric based on absolute population 
HG_instant <- POP_PERMITS |>
  mutate(permits_per1000 = (new_housing_units_permitted / population) * 1000)

#Standardizing 
#HG instant mean
HGI_mean <- HG_instant |>
  summarise(nationalmean_permits = mean(permits_per1000))|>
  pull(nationalmean_permits)

#HG instant Standard Deviation
HGI_sd <- HG_instant |>
  summarise(nationalstd_permits = sd(permits_per1000))|>
  pull(nationalstd_permits)

#HG instant Z score 
HGI_standardized <- HG_instant |>
  mutate(HGI_zscore = (permits_per1000 - HGI_mean)/ HGI_sd)
```
### **Instantaneous**: Cities with the Highest Housing Growth 
Baseline Value: **The national housing growth average(Z score) = 0**
```{r}
#| warning: false
highest_hgi_cities <- HGI_standardized |>
  select(GEOID, HGI_zscore, NAME, year)|>
  separate(NAME, into = c('City', 'State'), sep = ',\\s')|> 
  slice_max(HGI_zscore, n = 20)

highest_hgi_cities |>
  rename('CBSA'= 'GEOID')|>
  rename('Z Score' = 'HGI_zscore')|>
  rename('Year' = 'year')|>
  datatable(options=list(searching=FALSE, info=FALSE))|>
  formatRound(c('Z Score'))
```
### Constructing the Rate-Based Measure
```{r}
#‘rate-based’: metric based on pop growth over 5 years lookback window
HG_rate <- POP_PERMITS |>
  arrange(GEOID, year)|>
  group_by(GEOID)|>
  mutate(
    pop_5yrs_ago = lag(population, n = 5),
    growth = population - pop_5yrs_ago,
    housing_5yrs = roll_sumr(new_housing_units_permitted, 5, fill = NA),
    housing_growth_rate = (housing_5yrs / growth)*1000
  )|>
  filter(year >=2014)|>
  ungroup()

#Standardizing
#HG rate Mean 
HG_rate_mean <- HG_rate |>
  summarise(nationalmean_permits_rate = mean(housing_growth_rate, na.rm = TRUE))|>
  pull(nationalmean_permits_rate)

#HG rate Standard Deviation
HG_rate_sd <- HG_rate |>
  summarise(nationalstd_permits_rate = sd(housing_growth_rate, na.rm = TRUE))|>
  pull(nationalstd_permits_rate)

#HG rate Z score 
HG_rate_standardized <- HG_rate |>
  mutate(HG_rate_zscore = (housing_growth_rate - HG_rate_mean)/ HG_rate_sd)
```

### **Rate-Based**: Cities with the Highest Housing Growth 
Baseline Value: **The national housing growth average(Z score) = 0**
```{r}
highest_hgrate_cities <- HG_rate_standardized |>
  select(GEOID, HG_rate_zscore, NAME, year)|>
  separate(NAME, into = c('City', 'State'), sep = ',\\s')|> 
  slice_max(HG_rate_zscore, n = 20)

highest_hgrate_cities |>
  rename('CBSA'= 'GEOID')|>
  rename('Z Score' = 'HG_rate_zscore')|>
  rename('Year' = 'year')|>
  datatable(options=list(searching=FALSE, info=FALSE))|>
  formatRound(c('Z Score'))
```

### Constructing the Composite Measure
```{r}
HG_composite <- HG_rate_standardized |>
  inner_join(HGI_standardized, join_by(GEOID, year))|>
  mutate(composite_score = (HGI_zscore + HG_rate_zscore)/2)|>
  select(GEOID, composite_score, NAME.x, year)|>
  separate(NAME.x, into = c('City', 'State'), sep = ',\\s')
```
### Composite score: Cities with the Highest Housing Growth 
```{r}
HG_composite_high<- HG_composite |>
  slice_max(composite_score, n=20)

HG_composite_high |>
  rename('CBSA'= 'GEOID')|>
  rename('Composite Score' = 'composite_score')|>
  rename('Year' = 'year')|>
  datatable(options=list(searching=FALSE, info=FALSE))|>
  formatRound(c('Composite Score'))
```
### Composite score: Cities with the Lowest Housing Growth 
```{r}
HG_composite_low <- HG_composite |>
  slice_min(composite_score, n=20)

HG_composite_low |>
  rename('CBSA'= 'GEOID')|>
  rename('Composite Score' = 'composite_score')|>
  rename('Year' = 'year')|>
  datatable(options=list(searching=FALSE, info=FALSE))|>
  formatRound(c('Composite Score'))
```
## Task 6: Visualization
### 1. Cities with the Highest Housing Growth Rates
```{r}
#| warning: false
HG_rate_standardized |>
  ggplot(aes(x = year, y = HG_rate_zscore, group = GEOID, color = factor(GEOID))) +
  geom_line(size = .8) +
  gghighlight(max(HG_rate_zscore) > 3, 
              use_direct_label = FALSE,
              unhighlighted_params = list(size = 0.4, alpha = 0.3)) +
  scale_color_brewer(palette='Paired', name = "GEOID")+
  xlab("Year") + 
  ylab("Z-Score") + 
  labs(title = "Housing Growth Z-Scores by CBSA", ) +
  theme_bw() +
  theme(legend.position = "bottom")
```
### 2. Housing Growth In Relation to Population Growth
```{r}
#| warning: false
pop_growth <- POPULATION |>
  filter(year %in% c(2009, 2023)) |>       
  select(GEOID, year, population) |>
  pivot_wider(names_from = year, values_from = population, 
              names_prefix = "pop_") |> 
  filter(pop_2023 > pop_2009)|>
  mutate(pop_increase = pop_2023 - pop_2009)|>
  arrange(desc(pop_increase))

#pulling the geoid where there is population growth in the study period
pop_growth_geoid <- pop_growth |>
  pull(GEOID)

HG_rate_standardized |>
  ggplot(aes(x = year, y = HG_rate_zscore, group = GEOID, color = GEOID %in% pop_growth_geoid)) +
  geom_line() +
  scale_color_manual(values = c("TRUE" = "darkorchid", "FALSE" = "gray85"),
                     name = NULL,                     # removes the legend title
                     labels = c("FALSE" = "Other CBSA", "TRUE" = "Population Growth")) +
  gghighlight(max(HG_rate_zscore) > 3, 
              use_direct_label = FALSE,
              unhighlighted_params = list(size = 0.4, alpha = 0.3)) +
  xlab("Year") + 
  ylab("Z-Score") + 
  labs(title = "Highest Housing Growth Z-Scores by CBSA with Population Growth") +
  theme_bw()+
  theme(legend.position = "bottom") 
```

### 3. data viz for highest rent burden
```{r}
rb_standardized |>
  ggplot(aes(x = year, y = rb_zscore, group = GEOID, color = factor(GEOID))) +
  geom_line(size = .8) +
  gghighlight(max(rb_zscore, na.rm = TRUE) > 3.5, use_direct_label = FALSE,
              unhighlighted_params = list(size = 0.4, alpha = 0.3)) +
  scale_color_brewer(palette='Paired', name = "GEOID")+
  xlab("Year") + 
  ylab("Z-Score") + 
  labs(title = "Rent Burden Z-Scores by CBSA", ) +
  theme_bw() +
  theme(legend.position = "bottom")
```
[INSERT thought process]

### 3.2 data viz for highest rent burden
```{r}
states_rb_standardized <- rb_standardized |>
  filter(!str_detect(NAME.x, "PR Metro Area|PR Micro Area|Micro Area"))

states_rb_standardized |>
  ggplot(aes(x = year, y = rb_zscore, group = GEOID, color = factor(GEOID))) +
  geom_line(size = .8) +
  gghighlight(max(rb_zscore, na.rm = TRUE) > 2.6, use_direct_label = FALSE,
              unhighlighted_params = list(size = .3, alpha = 0.3)) +
  scale_color_brewer(palette='Paired', name = "GEOID")+
  xlab("Year") + 
  ylab("Z-Score") + 
  labs(title = "Rent Burden Z-Scores by CBSA", ) +
  theme_bw() +
  theme(legend.position = "bottom")
```

### 4. had a decrease in rent burden over time 
```{r}
rb_decrease <- states_rb_standardized |>
  filter(year %in% c(2009, 2023)) |> 
  select(GEOID, NAME.x, year, rb_zscore) |>
  pivot_wider(names_from = year, values_from = rb_zscore, 
              names_prefix = "rb_") |> 
  filter(rb_2023 < rb_2009) |>
  mutate(rent_burden_decrease = rb_2023 - rb_2009)|>
  arrange(desc(rent_burden_decrease))|>
  slice_min(rent_burden_decrease, n=10)|>
  pull(GEOID)

#Base plot with "Other CBSA" (background)
ggplot() +
  geom_line(
    data = filter(states_rb_standardized, !(GEOID %in% rb_decrease)),
    aes(x = year, y = rb_zscore, group = GEOID),
    color = "gray65", size = 0.4, alpha = 0.6) +
  # Highlighted lines (on top)
  geom_line(
    data = filter(states_rb_standardized, GEOID %in% rb_decrease),
    aes(x = year, y = rb_zscore, group = GEOID),
    color = "deeppink4", size = 0.9) +
  xlab("Year") + 
  ylab("Z-Score") + 
  labs(title = "Rent Burden Z-Score over time by CBSA",
       subtitle = 'Dark Pink lines indicate CBSAs with the greatest decrease
       in rent burden over time') +
  theme_bw() +
  theme(legend.position = "bottom") 

```

## Policy Brief: Affordable Housing Program: YIMBY (Yes In My Backyard)
```{r}
#| results: 'hide'
#1
GF_rb <- rb_standardized |>
  filter(GEOID == 24500)|>
  summarise(avg_rb_zscore = mean(rb_zscore))|>
  pull(avg_rb_zscore)

#2
HG_rate_standardized |>
  filter(GEOID == 24500)|>
  select(year, growth, HG_rate_zscore)

#3
orlando_rb <- rb_standardized|>
  filter(GEOID == 36740)|>
  summarise(orlando_avg_rb = mean(rb_zscore))|>
  pull(orlando_avg_rb)

#4 
orlando_rb_2023 <- rb_standardized|>
  filter(GEOID == 36740)|>
  filter(year == 2023)|>
  pull(rb_zscore)

#5
#total Orlando Population
orlando_total_pop <- POPULATION|>
  filter(GEOID == 36740)|>
  filter(year == 2023)|>
  pull(population)

#total NAICS 102,1026,72 workers = 1573385 
WAGES2|>
  filter(GEOID == 36740)|>
  filter(INDUSTRY %in% c(102, 1026,72))|>
  filter(YEAR == 2023)|>
  summarise(worker_count = sum(EMPLOYMENT))


```

Affordable housing shortages are placing significant financial pressure on families and individuals across the United States. The purpose of this policy proposal is to share key findings and recommendations based on data from the Bureau of Labor Statistics (BLS) and the U.S. Census Bureau.

### **YIMBY Success: Great Falls, Montana**

Great Falls, Montana, offers a strong example of the YIMBY approach in action. The city’s average rent burden is significantly lower than the national average, meaning residents spend a smaller share of their income on housing compared to most U.S. households**(1)**. From 2018 to 2023, Great Falls experienced steady population growth while successfully keeping pace through the consistent issuance of new housing permits each year**(2)**. Although the city’s 2023 housing growth rate is slightly below the national average, the overall trend shows sustained improvement. Our sponsor from Montana endorses this Affordable Housing Program after witnessing these positive outcomes firsthand.

### The Challenge: Orlando, Florida

Inspired by this success, our sponsor from Orlando, Florida, is eager to adopt similar affordable housing strategies. Orlando currently ranks as the 8th highest city in rent burden, with a score of **`r round(orlando_rb, 1)`** (where the national average equals 0)**(3)**. From 2009 to 2023, Orlando’s rent burden score has steadily increased, reaching **`r round(orlando_rb_2023, 1)`** in 2023**(4)**.

Although Orlando’s population continues to grow each year and new housing permits are also on the rise, the persistent increase in rent burden suggests that housing supply is still lagging behind demand. This indicates a pressing need for expanded affordable housing initiatives.

### The Labor Force 

Orlando’s economy is heavily driven by its world-renowned theme parks, including Walt Disney World and Universal Studios, which contribute significantly to the local labor market. According to BLS data, the city has a particularly large workforce in Leisure and Hospitality (NAICS 1026) and Accommodation and Food Services (NAICS 72) sectors.

As of 2023, Orlando’s total population was approximately **`r round(orlando_total_pop / 1e6, 1)`** million, with employees in these industries accounting for 55.8% of the workforce**(5)**. Expanding affordable housing options for this majority of residents would not only improve quality of life but also strengthen the local and global tourism economy. By reducing rent burden, workers would have greater disposable income to spend on goods and services, stimulating further economic growth within the city.

### **Rent Burden and Housing Growth Metric**

To measure rent burden, I standardized the rent-to-income ratio for each U.S. city. A score of 0 represents the national average; higher scores indicate greater rent burden. Thus, Orlando’s 2023 score of **`r round(orlando_rb_2023, 1)`** shows that residents spend significantly more of their income on rent compared to the national average.

Similarly, the housing growth metric measures new housing permits relative to population growth. A score of 0 again represents the national average, while positive scores indicate faster-than-average housing expansion. These standardized measures allow for direct comparison across cities and help identify areas where affordable housing policies are most needed.